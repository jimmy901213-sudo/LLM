import streamlit as st
import os
import json
from langchain_ollama.chat_models import ChatOllama
from langchain_community.vectorstores import Chroma
from langchain_ollama.embeddings import OllamaEmbeddings
from pydantic import BaseModel, Field
from typing import List, Dict, Optional

# åŒ¯å…¥æ–°æ¨¡çµ„
from memory import MemoryManager
from algorithm_explorer import AlgorithmExplorer, StrategyName
from update_vectorstore import VectorstoreUpdater

# --- 1. å®šç¾© Pydantic Schema (æˆ‘å€‘çš„çµæ§‹åŒ–è¼¸å‡º) ---
# é€™å€‹ Schema å°‡å¼·åˆ¶ Llama 3 ä»¥æˆ‘å€‘æƒ³è¦çš„ JSON æ ¼å¼å›æ‡‰ [3, 4]
class MarketingContent(BaseModel):
    product_name: str = Field(description="ç”¢å“çš„å®˜æ–¹å…¨å")
    catchy_title: str = Field(description="å„ªåŒ–çš„ AIO/SEO æ¨™é¡Œï¼Œä¸è¶…é 60 å€‹å­—ç¬¦")
    experience_paragraph: str = Field(description="E-E-A-T åŒ–çš„ç¬¬ä¸€äººç¨±ä½¿ç”¨ç¶“é©—æ®µè½ï¼Œéœ€çµåˆä¸€å€‹çœŸå¯¦å ´æ™¯")
    features_bullets: List[str] = Field(description="å¾ç”¢å“äº‹å¯¦ä¸­æå–çš„ 3-5 å€‹æ ¸å¿ƒåŠŸèƒ½åˆ—è¡¨")
    semantic_tags: List[str] = Field(description="ç›¸é—œçš„èªç¾©é—œéµå­—å’Œå¯¦é«” (ä¾‹å¦‚ 'æˆ¶å¤–', 'æ´¾å°')")
    qa_pairs: List[Dict[str, str]] = Field(description="2-3 å€‹ Q&A å°ï¼Œæ ¼å¼ç‚º [{'q': '...', 'a': '...'}]")

# --- 2. ç³»çµ±åˆå§‹åŒ– (ç·©å­˜ä»¥æé«˜æ•ˆèƒ½) ---
@st.cache_resource
def load_system():
    # æª¢æŸ¥ ChromaDB æ˜¯å¦å­˜åœ¨
    db_path = "./chroma_db"
    if not os.path.exists(db_path):
        return None, None, None, "ChromaDB ç›®éŒ„æœªæ‰¾åˆ°ã€‚è«‹å…ˆé‹è¡Œ 'create_vectorstore.py'ã€‚", None, None, None

    try:
        # 1. åˆå§‹åŒ– LLM (çµæ§‹åŒ–è¼¸å‡º)
        llm = ChatOllama(model="llama3:8b", temperature=0.1)
        llm_structured = llm.with_structured_output(MarketingContent)
        
        # 2. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        embeddings = OllamaEmbeddings(model="nomic-embed-text")
        
        # 3. åŠ è¼‰å‘é‡æ•¸æ“šåº«
        vectorstore = Chroma(persist_directory=db_path, embedding_function=embeddings)
        
        # 4. å‰µå»ºå…©å€‹æª¢ç´¢å™¨
        retriever_products = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"filter": {"source": "product_db"}, "k": 1}
        )
        retriever_rules = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"filter": {"source": "aio_rules"}, "k": 5}
        )
        
        # 5. åˆå§‹åŒ–æ–°æ¨¡çµ„ï¼šMemoryã€AlgorithmExplorerã€VectorstoreUpdater
        memory_manager = MemoryManager()
        algorithm_explorer = AlgorithmExplorer(memory_manager)
        vectorstore_updater = VectorstoreUpdater(db_path)

        return llm_structured, retriever_products, retriever_rules, None, memory_manager, algorithm_explorer, vectorstore_updater
    except Exception as e:
        return None, None, None, f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼š{e}ã€‚è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œï¼Œä¸¦ä¸”æ‚¨å·²æ‹‰å– 'llama3:8b' å’Œ 'nomic-embed-text' æ¨¡å‹ã€‚", None, None, None

# --- 3. Streamlit ç•Œé¢ ---
st.set_page_config(layout="wide")
st.title("ğŸš€ AIO/SEO è¡ŒéŠ·å…§å®¹ç”Ÿæˆå™¨ (æœ¬åœ°ç‰ˆå¢å¼·ç‰ˆ)")
st.caption("æ•´åˆ Memoryã€æ¼”ç®—æ³•æ‘¸ç´¢ã€è‡ªæˆ‘æ›´æ–°çš„æ™ºèƒ½è¡ŒéŠ·æ–‡æ¡ˆç”Ÿæˆç³»çµ±")

# åŠ è¼‰ç³»çµ±
structured_llm, prod_retriever, rule_retriever, error_msg, memory_manager, algorithm_explorer, vectorstore_updater = load_system()

if error_msg:
    st.error(error_msg)
else:
    # é ‚éƒ¨çµ±è¨ˆé¢æ¿
    col1, col2, col3, col4 = st.columns(4)
    
    if memory_manager:
        stats = memory_manager.aggregate_feedback_stats()
        vs_stats = vectorstore_updater.get_vectorstore_stats()
        algo_stats = algorithm_explorer.get_strategy_performance_report()
        
        with col1:
            st.metric("ğŸ“š ç”Ÿæˆè¨˜éŒ„", len(memory_manager.get_all_records()), "æ¢")
        with col2:
            st.metric("â­ å¹³å‡è©•åˆ†", stats.get("average_score", 0), "/10")
        with col3:
            st.metric("ğŸ“š å‘é‡åº«æ–‡æª”", vs_stats.get("total_documents", 0), "å€‹")
        with col4:
            recommended_strategy = algorithm_explorer.get_recommended_strategy()
            st.metric("ğŸ¯ æ¨è–¦ç­–ç•¥", recommended_strategy or "å¾…è©•ä¼°", "")
    
    st.divider()
    
    # å·¦å´é‚Šæ¬„è¨­ç½®
    st.sidebar.header("âš™ï¸ è¨­ç½®é¢æ¿")
    
    # Tab 1: ä¸»è¦ç”Ÿæˆ
    tab1, tab2, tab3, tab4 = st.sidebar.tabs(["ç”Ÿæˆ", "Memory", "æ›´æ–°å‘é‡åº«", "çµ±è¨ˆ"])
    
    with tab1:
        st.subheader("ğŸ¯ å…§å®¹ç”Ÿæˆ")
        # æ”¯æ´éƒ¨åˆ†é—œéµå­—åŒ¹é…ï¼šä½¿ç”¨è€…å¯è¼¸å…¥éƒ¨åˆ†åç¨±æˆ–é¡åˆ¥ï¼Œé»æ“Šã€ŒğŸ” æœç´¢ç”¢å“ã€ä¾†åˆ—å‡ºåŒ¹é…é …
        product_query_input = st.text_input("è¼¸å…¥ç”¢å“åç¨±æˆ–é—œéµå­—", placeholder="ä¾‹å¦‚: X-100 æˆ– éŸ³ç®± æˆ– X-100 éŸ³ç®±")

        # æœç´¢æŒ‰éˆ•ï¼šåƒ…åœ¨æŒ‰ä¸‹æ™‚åŸ·è¡Œå‘é‡åº«æª¢ç´¢ï¼Œçµæœä¿å­˜åœ¨ session_state
        if st.button("ğŸ” æœç´¢ç”¢å“"):
            if product_query_input and vectorstore_updater:
                st.session_state.search_matches = vectorstore_updater.search_products(product_query_input, limit=50)
            else:
                st.session_state.search_matches = []

        # é¡¯ç¤ºæœç´¢çµæœï¼ˆè‹¥æœ‰ï¼‰
        matches = st.session_state.get("search_matches", [])
        selected_product_name: Optional[str] = None

        if matches:
            st.write(f"æ‰¾åˆ° {len(matches)} å€‹åŒ¹é…ï¼Œè«‹å¾ä¸‹æ–¹é¸æ“‡è¦ç”Ÿæˆçš„ç”¢å“ï¼š")
            product_choices = [f"{m['product_name']} ({m['category']})" for m in matches]
            chosen = st.selectbox("é¸æ“‡ç”¢å“ï¼ˆæˆ–ç•™ç©ºä½¿ç”¨åŸå§‹è¼¸å…¥ï¼‰", ["(ä½¿ç”¨åŸå§‹è¼¸å…¥)"] + product_choices)
            if chosen != "(ä½¿ç”¨åŸå§‹è¼¸å…¥)":
                selected_product_name = chosen.split(" (")[0]

            if st.checkbox("é¡¯ç¤ºåŒ¹é…è©³æƒ…"):
                for m in matches:
                    st.write(f"- {m['product_name']}  |  é¡åˆ¥: {m['category']}  |  åƒ¹æ ¼: {m.get('price','')}  | doc_id: {m.get('doc_id')}")

            if st.button("æ¸…é™¤æœç´¢çµæœ"):
                st.session_state.search_matches = []
        else:
            st.info("å°šæœªæœç´¢æˆ–æœªæ‰¾åˆ°åŒ¹é…é …ã€‚è«‹è¼¸å…¥é—œéµå­—ä¸¦æŒ‰ã€ğŸ” æœç´¢ç”¢å“ã€ã€‚")
        
        # æ¼”ç®—æ³•é¸æ“‡
        algorithm_mode = st.radio(
            "é¸æ“‡ç”Ÿæˆæ¨¡å¼",
            ["å–®ä¸€ç­–ç•¥", "æ‘¸ç´¢æ‰€æœ‰ç­–ç•¥"],
            help="å–®ä¸€ç­–ç•¥é€Ÿåº¦å¿«ï¼Œæ‘¸ç´¢æ¨¡å¼æœƒå˜—è©¦å¤šå€‹ç­–ç•¥"
        )
        
        if algorithm_mode == "å–®ä¸€ç­–ç•¥":
            selected_strategy = st.selectbox(
                "é¸æ“‡ç­–ç•¥",
                list(StrategyName),
                format_func=lambda x: x.value
            )
        else:
            selected_strategy = None
        
        if st.button("ğŸš€ ç”Ÿæˆå…§å®¹", use_container_width=True):
            # åŸºæ–¼éƒ¨åˆ†åŒ¹é…é¸æ“‡æœ€çµ‚æŸ¥è©¢å­—ä¸²
            product_query_final = (selected_product_name or product_query_input or "").strip()
            if not product_query_final:
                st.error("è«‹è¼¸å…¥ç”¢å“åç¨±æˆ–é¸æ“‡åŒ¹é…é …ç›®")
            else:
                with st.spinner("ç³»çµ±æ­£åœ¨æ€è€ƒ..."):
                    try:
                        # æª¢ç´¢ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æœ€çµ‚è§£æå‡ºçš„ç”¢å“åç¨±æˆ–åŸå§‹è¼¸å…¥ï¼‰
                        product_context_docs = prod_retriever.invoke(product_query_final)
                        product_context = "\n---\n".join([doc.page_content for doc in product_context_docs])

                        rule_context_docs = rule_retriever.invoke("æ‰€æœ‰ AIO/SEO/E-E-A-T è¡ŒéŠ·è¦å‰‡")
                        rule_context = "\n---\n".join([doc.page_content for doc in rule_context_docs])

                        json_schema_description = MarketingContent.model_json_schema()

                        if algorithm_mode == "å–®ä¸€ç­–ç•¥":
                            # å–®ä¸€ç­–ç•¥æ¨¡å¼
                            prompt = algorithm_explorer.get_strategy_prompt(
                                strategy_name=selected_strategy.value,
                                product_context=product_context,
                                rule_context=rule_context,
                                product_query=product_query_final,
                                json_schema=json_schema_description
                            )

                            response_obj = structured_llm.invoke(prompt)

                            # è¨˜éŒ„åˆ° Memory
                            memory_manager.add_generation_record(
                                query=product_query_final,
                                product_name=response_obj.product_name,
                                strategy=selected_strategy.value,
                                result=response_obj.model_dump()
                            )

                            # æ›´æ–°ç®—æ³•çµ±è¨ˆï¼ˆç¤ºä¾‹æ•¸å€¼ï¼Œå¯ç”±è©•åˆ†æ›¿æ›ï¼‰
                            algorithm_explorer.update_algorithm_stats(
                                selected_strategy.value,
                                success=True,
                                metrics={"quality": 8.0}
                            )

                            strategy_used = selected_strategy.value
                        else:
                            # æ‘¸ç´¢æ‰€æœ‰ç­–ç•¥æ¨¡å¼
                            def llm_call(prompt):
                                return structured_llm.invoke(prompt)

                            exploration_results = algorithm_explorer.explore_all_strategies(
                                llm_invoke_func=llm_call,
                                product_context=product_context,
                                rule_context=rule_context,
                                product_query=product_query_final,
                                json_schema=json_schema_description
                            )

                            # é¸æ“‡æœ€ä½³ç­–ç•¥
                            best_strategy = algorithm_explorer.select_best_strategy(exploration_results)

                            if best_strategy and exploration_results["results"][best_strategy]["success"]:
                                response_obj = exploration_results["results"][best_strategy]["result"]
                            else:
                                st.error("æ²’æœ‰æˆåŠŸçš„ç­–ç•¥")
                                st.stop()

                            # è¨˜éŒ„åˆ° Memory
                            memory_manager.add_generation_record(
                                query=product_query_final,
                                product_name=response_obj.product_name,
                                strategy=f"æ‘¸ç´¢_{best_strategy}",
                                result=response_obj.model_dump()
                            )

                            strategy_used = f"æ‘¸ç´¢_{best_strategy}"

                        # åœ¨ä¸»å€é¡¯ç¤ºçµæœ
                        st.session_state.last_result = response_obj
                        st.session_state.last_strategy = strategy_used

                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±æ•—ï¼š{e}")
    
    with tab2:
        st.subheader("ğŸ’¾ Memory ç³»çµ±")
        
        memory_options = st.radio(
            "Memory æ“ä½œ",
            ["æŸ¥çœ‹æ­·å²", "æŸ¥çœ‹åé¥‹", "æ­·å²æœå°‹"]
        )
        
        if memory_options == "æŸ¥çœ‹æ­·å²":
            records = memory_manager.get_all_records()
            if records:
                st.write(f"å…± {len(records)} æ¢è¨˜éŒ„")
                for record in records[-5:]:
                    with st.expander(f"{record['product_name']} - {record['timestamp'][:10]}"):
                        st.write(f"æŸ¥è©¢: {record['query']}")
                        st.write(f"ç­–ç•¥: {record['strategy']}")
                        st.write(f"è©•åˆ†: {record.get('user_score', 'N/A')}")
            else:
                st.info("æš«ç„¡è¨˜éŒ„")
        
        elif memory_options == "æŸ¥çœ‹åé¥‹":
            stats = memory_manager.aggregate_feedback_stats()
            st.write(f"å¹³å‡è©•åˆ†: {stats.get('average_score', 0):.1f}/10")
            st.write(f"ç¸½åé¥‹: {stats.get('total_feedback', 0)} æ¢")
            
            if stats.get("distribution"):
                st.bar_chart(stats["distribution"])
        
        elif memory_options == "æ­·å²æœå°‹":
            search_query = st.text_input("æœå°‹ç”¢å“åç¨±")
            if search_query:
                similar = memory_manager.get_similar_past_results(search_query, limit=10)
                for record in similar:
                    st.write(f"âœ… {record['product_name']} ({record['strategy']})")
    
    with tab3:
        st.subheader("ğŸ“¤ è‡ªæˆ‘æ›´æ–°")
        
        update_mode = st.radio(
            "æ›´æ–°æ¨¡å¼",
            ["å–®å€‹ç”¢å“", "æ‰¹é‡åŒ¯å…¥"]
        )
        
        if update_mode == "å–®å€‹ç”¢å“":
            product_name = st.text_input("ç”¢å“åç¨±")
            description = st.text_area("ç”¢å“æè¿°")
            features = st.text_area("åŠŸèƒ½ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰").split("\n") if st.text_area("åŠŸèƒ½ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰") else []
            price = st.text_input("åƒ¹æ ¼ï¼ˆå¯é¸ï¼‰")
            
            if st.button("æ·»åŠ ç”¢å“"):
                if product_name and description:
                    result = vectorstore_updater.add_product(
                        product_name=product_name,
                        description=description,
                        features=[f for f in features if f],
                        price=price or None
                    )
                    if result["success"]:
                        st.success(result["message"])
                    else:
                        st.error(result["message"])
        
        else:
            uploaded_file = st.file_uploader("ä¸Šå‚³ JSON æª”æ¡ˆ", type="json")
            if uploaded_file:
                try:
                    data = json.load(uploaded_file)
                    
                    # åˆ¤æ–·æ˜¯ç”¢å“é‚„æ˜¯è¦å‰‡
                    if isinstance(data, list) and len(data) > 0:
                        if "rule_text" in data[0]:
                            result = vectorstore_updater.batch_import_rules(uploaded_file.name)
                        else:
                            result = vectorstore_updater.batch_import_products(uploaded_file.name)
                        
                        st.success(result["message"])
                except Exception as e:
                    st.error(f"åŒ¯å…¥å¤±æ•—ï¼š{e}")
    
    with tab4:
        st.subheader("ğŸ“Š çµ±è¨ˆä¿¡æ¯")
        
        stat_type = st.radio(
            "çµ±è¨ˆé¡å‹",
            ["å‘é‡åº«", "æ¼”ç®—æ³•", "Memory"]
        )
        
        if stat_type == "å‘é‡åº«":
            vs_stats = vectorstore_updater.get_vectorstore_stats()
            st.write(f"ç¸½æ–‡æª”æ•¸: {vs_stats.get('total_documents', 0)}")
            st.write(f"ç”¢å“: {vs_stats.get('products', 0)}")
            st.write(f"è¦å‰‡: {vs_stats.get('rules', 0)}")
            st.write(f"ç¸½æ›´æ–°æ¬¡æ•¸: {vs_stats.get('total_updates', 0)}")
        
        elif stat_type == "æ¼”ç®—æ³•":
            algo_report = algorithm_explorer.get_strategy_performance_report()
            for strategy, perf in algo_report.items():
                st.write(f"**{strategy}**")
                st.write(f"  æˆåŠŸç‡: {perf['success_rate']*100:.0f}%")
                st.write(f"  å¹³å‡è©•åˆ†: {perf['average_score']:.1f}")
                st.write(f"  æ¬Šé‡: {perf['weight']:.2f}")
        
        elif stat_type == "Memory":
            stats = memory_manager.aggregate_feedback_stats()
            st.json(stats)
    
    # ä¸»å€é¡¯ç¤ºçµæœ
    st.header("ğŸ“„ ç”Ÿæˆçµæœ")
    
    if "last_result" in st.session_state:
        response_obj = st.session_state.last_result
        
        st.subheader(f"âœ… {response_obj.product_name}")
        
        st.markdown(f"### {response_obj.catchy_title}")
        st.divider()
        
        st.markdown("#### E-E-A-T ç¶“é©—æ®µè½:")
        st.markdown(response_obj.experience_paragraph)
        
        st.markdown("#### æ ¸å¿ƒåŠŸèƒ½:")
        st.markdown("\n".join(f"- {item}" for item in response_obj.features_bullets))
        
        st.markdown("#### Q&A éƒ¨åˆ†:")
        for pair in response_obj.qa_pairs:
            st.markdown(f"**Q: {pair['q']}**")
            st.markdown(f"A: {pair['a']}")
        
        st.markdown("#### èªç¾©æ¨™ç±¤:")
        st.markdown(", ".join(response_obj.semantic_tags))
        
        st.markdown("---")
        
        # åé¥‹å’Œè©•åˆ†
        col1, col2 = st.columns(2)
        with col1:
            user_score = st.slider("è©•åˆ†", 0, 10, 5, help="0 = å¾ˆå·®ï¼Œ10 = å®Œç¾")
        with col2:
            user_comment = st.text_input("è©•è«–")
        
        if st.button("ä¿å­˜è©•åˆ†"):
            record_id = memory_manager.persistent_records[-1]["id"]
            memory_manager.add_feedback(
                record_id=record_id,
                score=user_score,
                comment=user_comment
            )
            st.success("âœ… è©•åˆ†å·²ä¿å­˜")
        
        st.subheader("åŸå§‹ JSON è¼¸å‡º (ç”¨æ–¼ API):")
        st.json(response_obj.model_dump_json())
    
    else:
        st.info("ğŸ‘ˆ å¾å·¦å´é¸æ“‡ã€Œç”Ÿæˆã€æ¨™ç±¤é–‹å§‹ä½¿ç”¨")